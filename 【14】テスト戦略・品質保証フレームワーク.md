システムの信頼性を確保するための包括的なテスト戦略を提供します。
# テスト戦略・品質保証フレームワーク

## 1. テストピラミッド

```
              ┌─────────────────┐
              │   E2Eテスト     │  ← 少数だが重要
              │  (10-20件)      │
              └────────┬────────┘
                       │
         ┌─────────────┴─────────────┐
         │     統合テスト              │  ← 中程度
         │    (50-100件)               │
         └──────────┬──────────────────┘
                    │
    ┌───────────────┴───────────────────┐
    │        ユニットテスト               │  ← 多数
    │       (200-500件)                   │
    └─────────────────────────────────────┘
```

### テスト配分の原則

```yaml
ユニットテスト (70%):
  - 個別関数・メソッドの動作確認
  - 高速（< 0.1秒/テスト）
  - モック・スタブを活用
  - カバレッジ目標: 80%以上

統合テスト (20%):
  - コンポーネント間の連携確認
  - データベース・外部API連携
  - 中速（< 5秒/テスト）
  - テストデータベース使用

E2Eテスト (10%):
  - ユーザーシナリオ全体の確認
  - 実環境に近い設定
  - 低速（< 60秒/テスト）
  - 主要な業務フロー網羅
```

---

## 2. ユニットテストの実装

### テストフレームワーク: pytest

```python
# tests/test_pub_collector.py
import pytest
from unittest.mock import Mock, patch, AsyncMock
from app.agents.pub_collector import PUBCollector

class TestPUBCollector:
    """PUB収集エージェントのユニットテスト"""
    
    @pytest.fixture
    def collector(self):
        """テスト用のCollectorインスタンス"""
        return PUBCollector(openai_api_key="test-key")
    
    @pytest.fixture
    def sample_html(self):
        """テスト用のHTMLサンプル"""
        return """
        <html>
            <body>
                <h1>株式会社サンプル</h1>
                <div class="info">
                    <p>設立: 2020年4月1日</p>
                    <p>従業員数: 45名</p>
                    <p>所在地: 東京都渋谷区</p>
                </div>
            </body>
        </html>
        """
    
    def test_clean_html_removes_scripts(self, collector, sample_html):
        """HTMLクリーニングでscriptタグが削除されることを確認"""
        html_with_script = sample_html + "<script>alert('test')</script>"
        
        cleaned = collector._clean_html(html_with_script)
        
        assert "script" not in cleaned.lower()
        assert "alert" not in cleaned
        assert "株式会社サンプル" in cleaned
    
    @pytest.mark.asyncio
    async def test_extract_with_llm_returns_structured_data(self, collector):
        """LLM抽出が構造化データを返すことを確認"""
        mock_response = Mock()
        mock_response.choices = [
            Mock(message=Mock(content='{"company_name": "テスト株式会社"}'))
        ]
        
        with patch.object(
            collector.llm.chat.completions,
            'create',
            return_value=AsyncMock(return_value=mock_response)
        ):
            result = await collector._extract_with_llm(
                content="テスト株式会社について",
                url="https://example.com"
            )
        
        assert result["company_name"] == "テスト株式会社"
    
    def test_to_observations_converts_correctly(self, collector):
        """データを観測形式に正しく変換することを確認"""
        data = {
            "company_name": "テスト株式会社",
            "company_name_confidence": 0.95,
            "employee_count": 50,
            "employee_count_confidence": 0.8
        }
        
        observations = collector._to_observations(
            data,
            source_url="https://example.com"
        )
        
        assert len(observations) == 2
        assert observations[0]["field"] == "company_name"
        assert observations[0]["source_tag"] == "PUB"
        assert observations[0]["confidence"] == 0.95
    
    @pytest.mark.asyncio
    async def test_fetch_webpage_handles_timeout(self, collector):
        """Webページ取得がタイムアウトを処理することを確認"""
        with patch('playwright.async_api.async_playwright') as mock_pw:
            mock_pw.return_value.__aenter__.return_value.chromium.launch.side_effect = TimeoutError()
            
            with pytest.raises(TimeoutError):
                await collector._fetch_webpage("https://example.com")
    
    def test_field_mapping_is_correct(self, collector):
        """フィールドマッピングが正しいことを確認"""
        data = {"company_name": "Test"}
        obs = collector._to_observations(data, "url")[0]
        
        assert obs["section"] == "basic_info"
        assert obs["field"] == "company_name"


# tests/test_conflict_detector.py
from app.agents.conflict_detector import ConflictDetector

class TestConflictDetector:
    """矛盾検出エンジンのユニットテスト"""
    
    @pytest.fixture
    def detector(self):
        return ConflictDetector()
    
    @pytest.fixture
    def observations_with_conflict(self):
        """矛盾のある観測データ"""
        return [
            {
                "id": "obs1",
                "field": "arr",
                "value_number": 300_000_000,
                "source_tag": "CONF",
                "as_of": "2024-09-30"
            },
            {
                "id": "obs2",
                "field": "arr",
                "value_number": 450_000_000,
                "source_tag": "INT",
                "as_of": "2024-10-01"
            }
        ]
    
    def test_detect_conflicts_finds_large_deviation(
        self, detector, observations_with_conflict
    ):
        """大きな差異を検出することを確認"""
        conflicts = detector.detect_conflicts(observations_with_conflict)
        
        assert len(conflicts) == 1
        assert conflicts[0]["deviation_pct"] == 50.0
        assert conflicts[0]["severity"] == "critical"
    
    def test_no_conflict_for_small_deviation(self, detector):
        """小さな差異は矛盾とみなさないことを確認"""
        observations = [
            {"id": "obs1", "field": "arr", "value_number": 300_000_000, "source_tag": "CONF"},
            {"id": "obs2", "field": "arr", "value_number": 305_000_000, "source_tag": "PUB"}
        ]
        
        conflicts = detector.detect_conflicts(observations)
        
        assert len(conflicts) == 0
    
    def test_auto_resolve_selects_highest_priority(
        self, detector, observations_with_conflict
    ):
        """自動解決が最優先ソースを選択することを確認"""
        conflict = {
            "observation_ids": ["obs1", "obs2"],
            "deviation_pct": 50
        }
        
        resolution = detector.auto_resolve(
            conflict, observations_with_conflict
        )
        
        assert resolution["resolution"] == "use_highest_priority"
        assert "CONF" in resolution["reason"]


# tests/test_report_generator.py
class TestReportGenerator:
    """レポート生成エンジンのユニットテスト"""
    
    @pytest.fixture
    def generator(self):
        return ReportGenerator(openai_api_key="test-key")
    
    def test_organize_sections_groups_correctly(self, generator):
        """セクション構成が正しく組み立てられることを確認"""
        observations = [
            {"field": "company_name", "value": "Test"},
            {"field": "arr", "value": 300_000_000}
        ]
        
        sections = generator._organize_sections(observations, [])
        
        assert len(sections) > 0
        assert any(s["title"] == "概要" for s in sections)
    
    @pytest.mark.asyncio
    async def test_generate_section_content_uses_llm(self, generator):
        """セクション本文生成がLLMを使用することを確認"""
        mock_response = Mock()
        mock_response.choices = [
            Mock(message=Mock(content="テスト本文"))
        ]
        
        with patch.object(
            generator.llm.chat.completions,
            'create',
            return_value=AsyncMock(return_value=mock_response)
        ):
            content = await generator._generate_section_content(
                "概要", {}, {"company_name": "Test"}
            )
        
        assert "テスト本文" in content
```

### テスト実行とカバレッジ

```bash
# すべてのテストを実行
pytest

# カバレッジ付きで実行
pytest --cov=app --cov-report=html --cov-report=term

# 特定のテストのみ実行
pytest tests/test_pub_collector.py

# 並列実行（高速化）
pytest -n auto

# マーカーで選択的に実行
pytest -m "not slow"  # 遅いテストをスキップ
```

---

## 3. 統合テストの実装

### データベース統合テスト

```python
# tests/integration/test_observation_workflow.py
import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.models import Base, Case, Observation

@pytest.fixture(scope="function")
def test_db():
    """テスト用データベース"""
    # テスト用のインメモリDB
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)
    
    Session = sessionmaker(bind=engine)
    session = Session()
    
    yield session
    
    session.close()

class TestObservationWorkflow:
    """観測データのワークフロー統合テスト"""
    
    def test_case_with_observations(self, test_db):
        """案件と観測データの連携を確認"""
        # 案件作成
        case = Case(
            company_name="テスト株式会社",
            stage="early",
            status="draft"
        )
        test_db.add(case)
        test_db.commit()
        
        # 観測データ追加
        obs = Observation(
            case_id=case.id,
            section="basic_info",
            field="company_name",
            value_string="テスト株式会社",
            source_tag="PUB",
            evidence="https://example.com",
            as_of=datetime.now(),
            confidence=1.0
        )
        test_db.add(obs)
        test_db.commit()
        
        # 関連確認
        retrieved_case = test_db.query(Case).filter_by(
            company_name="テスト株式会社"
        ).first()
        
        assert retrieved_case is not None
        assert len(retrieved_case.observations) == 1
        assert retrieved_case.observations[0].field == "company_name"
    
    def test_cascade_delete(self, test_db):
        """カスケード削除の動作確認"""
        case = Case(company_name="削除テスト", stage="seed", status="draft")
        test_db.add(case)
        test_db.commit()
        
        obs = Observation(
            case_id=case.id,
            field="test",
            value_string="test",
            source_tag="PUB",
            evidence="url",
            as_of=datetime.now()
        )
        test_db.add(obs)
        test_db.commit()
        
        case_id = case.id
        
        # 案件削除
        test_db.delete(case)
        test_db.commit()
        
        # 観測データも削除されることを確認
        remaining_obs = test_db.query(Observation).filter_by(
            case_id=case_id
        ).count()
        
        assert remaining_obs == 0
```

### API統合テスト

```python
# tests/integration/test_api.py
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

class TestCasesAPI:
    """Cases APIの統合テスト"""
    
    def test_create_case_full_flow(self):
        """案件作成の全フローを確認"""
        # 案件作成
        response = client.post(
            "/api/v1/cases",
            json={
                "company_name": "API テスト株式会社",
                "stage": "early",
                "website_url": "https://example.com"
            },
            headers={"Authorization": "Bearer test-token"}
        )
        
        assert response.status_code == 201
        data = response.json()
        assert "id" in data
        case_id = data["id"]
        
        # 案件取得
        response = client.get(
            f"/api/v1/cases/{case_id}",
            headers={"Authorization": "Bearer test-token"}
        )
        
        assert response.status_code == 200
        assert response.json()["company_name"] == "API テスト株式会社"
        
        # 観測データ確認（PUB収集完了後）
        import time
        time.sleep(5)  # バックグラウンド処理待機
        
        response = client.get(
            f"/api/v1/cases/{case_id}/observations",
            headers={"Authorization": "Bearer test-token"}
        )
        
        assert response.status_code == 200
        observations = response.json()
        assert len(observations) > 0
```

---

## 4. E2Eテストの実装

### Playwright によるE2Eテスト

```python
# tests/e2e/test_case_creation_flow.py
import pytest
from playwright.sync_api import Page, expect

class TestCaseCreationFlow:
    """案件作成フローのE2Eテスト"""
    
    @pytest.fixture(scope="function")
    def authenticated_page(self, page: Page):
        """認証済みページ"""
        page.goto("http://localhost:3000/login")
        page.fill('input[name="email"]', "test@example.com")
        page.fill('input[name="password"]', "password")
        page.click('button[type="submit"]')
        page.wait_for_url("**/dashboard")
        return page
    
    def test_create_case_and_view_results(self, authenticated_page: Page):
        """案件作成から結果確認までの全フロー"""
        page = authenticated_page
        
        # ダッシュボードで新規案件ボタンをクリック
        page.click('text="新規案件"')
        page.wait_for_url("**/cases/new")
        
        # フォーム入力
        page.fill('input[name="company_name"]', "E2E テスト株式会社")
        page.select_option('select[name="stage"]', "early")
        page.fill('input[name="website_url"]', "https://example.com")
        
        # 送信
        page.click('button[type="submit"]')
        
        # 案件詳細ページにリダイレクト
        page.wait_for_url("**/cases/*")
        
        # 会社名が表示されることを確認
        expect(page.locator("h1")).to_contain_text("E2E テスト株式会社")
        
        # PUB収集の進捗が表示されることを確認
        expect(page.locator('text="PUB収集中"')).to_be_visible(timeout=5000)
        
        # 完了を待つ
        expect(page.locator('text="PUB収集完了"')).to_be_visible(timeout=60000)
        
        # 観測データが表示されることを確認
        page.click('text="情報収集"')
        expect(page.locator('table')).to_be_visible()
        
        # 最低1件のデータがあることを確認
        rows = page.locator('table tbody tr')
        expect(rows).to_have_count_greater_than(0)
    
    def test_conflict_resolution_flow(self, authenticated_page: Page):
        """矛盾解決フローのE2E"""
        page = authenticated_page
        
        # 矛盾のある案件を開く
        page.goto("http://localhost:3000/cases/test-case-with-conflict")
        
        # 矛盾タブを開く
        page.click('text="矛盾・要確認"')
        
        # 矛盾が表示されることを確認
        expect(page.locator('.conflict-card')).to_be_visible()
        
        # 解決ボタンをクリック
        page.click('.conflict-card button:has-text("解決する")')
        
        # モーダルが開く
        expect(page.locator('.modal')).to_be_visible()
        
        # 値を選択
        page.click('input[value="source_a"]')
        
        # 理由を入力
        page.fill('textarea[name="reason"]', "最新のデータを採用")
        
        # 承認
        page.click('button:has-text("承認")')
        
        # モーダルが閉じる
        expect(page.locator('.modal')).not_to_be_visible()
        
        # 矛盾が解決済みになることを確認
        expect(page.locator('.conflict-card.resolved')).to_be_visible()
```

---

## 5. パフォーマンステスト

### ロードテスト（Locust）

```python
# tests/performance/locustfile.py
from locust import HttpUser, task, between

class FundAutomationUser(HttpUser):
    """負荷テスト用のユーザーシミュレーション"""
    wait_time = between(1, 5)
    
    def on_start(self):
        """テスト開始時に実行（ログイン）"""
        response = self.client.post("/api/v1/auth/login", json={
            "email": "test@example.com",
            "password": "password"
        })
        self.token = response.json()["access_token"]
        self.headers = {"Authorization": f"Bearer {self.token}"}
    
    @task(3)
    def list_cases(self):
        """案件一覧取得（頻度: 高）"""
        self.client.get(
            "/api/v1/cases",
            headers=self.headers,
            name="/cases [LIST]"
        )
    
    @task(2)
    def get_case_detail(self):
        """案件詳細取得（頻度: 中）"""
        self.client.get(
            f"/api/v1/cases/test-case-id",
            headers=self.headers,
            name="/cases/:id [GET]"
        )
    
    @task(1)
    def create_case(self):
        """案件作成（頻度: 低）"""
        self.client.post(
            "/api/v1/cases",
            headers=self.headers,
            json={
                "company_name": f"Load Test Company {self.task_id}",
                "stage": "early",
                "website_url": "https://example.com"
            },
            name="/cases [CREATE]"
        )
    
    @task(2)
    def get_observations(self):
        """観測データ取得"""
        self.client.get(
            "/api/v1/cases/test-case-id/observations",
            headers=self.headers,
            name="/observations [LIST]"
        )

# 実行方法:
# locust -f locustfile.py --host=http://localhost:8000
# Web UI: http://localhost:8089
```

### パフォーマンス目標

```yaml
レスポンスタイム（P95）:
  - API (GET): < 200ms
  - API (POST): < 500ms
  - LLM抽出: < 10秒
  - レポート生成: < 30秒

スループット:
  - 同時ユーザー: 50人
  - リクエスト/秒: 100 req/s
  - 1日の案件処理: 100件

リソース使用率:
  - CPU: < 70%
  - メモリ: < 80%
  - DB接続: < 80%
```

---

## 6. セキュリティテスト

### OWASP Top 10 対策チェックリスト

```yaml
□ A01: アクセス制御の不備
  □ JWT検証のテスト
  □ 権限チェックのテスト
  □ 水平権限昇格の防止

□ A02: 暗号化の失敗
  □ HTTPS強制
  □ パスワードハッシュ化（bcrypt）
  □ 機密データの暗号化

□ A03: インジェクション
  □ SQLインジェクション対策（パラメータ化クエリ）
  □ コマンドインジェクション対策
  □ プロンプトインジェクション対策

□ A04: 安全でない設計
  □ セキュアバイデザイン
  □ 脅威モデリング

□ A05: セキュリティの設定ミス
  □ デフォルトパスワード無効化
  □ 不要なサービス停止
  □ エラーメッセージの適切化

□ A06: 脆弱で古いコンポーネント
  □ 依存関係の定期更新
  □ 脆弱性スキャン（Snyk, Dependabot）

□ A07: 認証とセッション管理の不備
  □ MFA実装
  □ セッションタイムアウト
  □ 安全なパスワードポリシー

□ A08: ソフトウェアとデータの整合性
  □ コード署名
  □ 改ざん検知

□ A09: ログとモニタリングの不備
  □ 全アクションのログ記録
  □ 異常検知アラート

□ A10: サーバサイドリクエストフォージェリ（SSRF）
  □ URL検証
  □ ホワイトリスト方式
```

### 自動セキュリティスキャン

```yaml
# .github/workflows/security-scan.yml
name: Security Scan

on: [push, pull_request]

jobs:
  dependency-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run Snyk
        uses: snyk/actions/python@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
  
  code-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run Bandit
        run: |
          pip install bandit
          bandit -r app/ -f json -o bandit-report.json
      
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: bandit-report
          path: bandit-report.json
```

---

## 7. 継続的インテグレーション（CI）

### GitHub Actions設定

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        ports:
          - 6379:6379
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
      
      - name: Run linter
        run: |
          flake8 app/ --max-line-length=100
          black app/ --check
          mypy app/
      
      - name: Run unit tests
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test
          REDIS_URL: redis://localhost:6379
        run: |
          pytest tests/unit \
            --cov=app \
            --cov-report=xml \
            --cov-report=term
      
      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test
        run: |
          pytest tests/integration -v
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
      
      - name: Build Docker image
        run: docker build -t fund-automation:${{ github.sha }} .
      
      - name: Run security scan
        run: |
          docker run --rm -v $(pwd):/app aquasec/trivy image fund-automation:${{ github.sha }}
```

---

## 8. 品質ゲート

### リリース前の必須チェック

```markdown
□ コード品質
  □ テストカバレッジ ≥ 80%
  □ Linter エラー 0件
  □ 型チェック（mypy）エラー 0件
  □ コードレビュー承認 ≥ 2名

□ テスト
  □ ユニットテスト 100% PASS
  □ 統合テスト 100% PASS
  □ E2E 主要シナリオ PASS
  □ パフォーマンステスト目標達成

□ セキュリティ
  □ 脆弱性スキャン Critical/High 0件
  □ 依存関係の最新化
  □ セキュリティレビュー完了

□ ドキュメント
  □ API仕様書更新
  □ README更新
  □ CHANGELOG記載

□ デプロイ準備
  □ 環境変数設定確認
  □ データベースマイグレーション確認
  □ ロールバック手順確認
  □ モニタリング設定確認
```

---

このテスト戦略により、システムの信頼性と品質を高いレベルで維持できます。テストは「コスト」ではなく「投資」として捉え、継続的に改善していくことが重要です。

