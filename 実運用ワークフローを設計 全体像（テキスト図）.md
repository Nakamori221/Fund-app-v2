了解です。Gemini と GPT（OpenAI API）＋ MCP（Model Context Protocol）**だけ**を使って、  
「PUB/EXT/ANL＝自動」「CONF＝半自動」「INT＝不足だけ最後に取得」「資料＝自動最終化」まで回す**実運用ワークフロー**を設計しました。  
実装は段階導入（MVP→拡張）で進められるように、**役割分担／データ設計／エージェント設計／疑似コード**まで落としています。

---

# 全体像（テキスト図）

```
[トリガ] 案件登録/更新
   │
   ├─(1) PUB収集Bot → 公式/PR/登記/採用/ブログ/ニュースのクロール&抽出
   ├─(2) EXT収集Bot → Similarweb/G2/Crunchbase等のAPIコール（可能範囲）
   ├─(3) 正規化Bot  → 事実/数値の正規化・重複排除・出典付与
   │
   ├─(4) ギャップ検出Bot → 未充足項目の洗い出し（質問化）→ INT質問票/CONF依頼票生成
   │
   ├─(5) CONFインジェスタ（半自動）
   │       └─ MCP経由で GDrive/Box/Notion から資料取り込み
   │       └─ GPTがフォームで項目抽出（条項/CapTable/モデル前提）→ 人間ワンクリック承認
   │
   ├─(6) ANL計算エンジン（自動）
   │       └─ LTV/CAC・TAM/SAM/SOM・Comps・DCF・シナリオ（穴は「pending」フラグ）
   │
   ├─(7) INT支援Bot（不足のみ）
   │       └─ 質問票提示→議事メモ要約→欠落セル自動充填→再計算
   │
   └─(8) 資料ビルダー（自動）
           └─ IC版/LP版（機微自動マスキング）をMarkdown/Google Docsに出力
```

---

# 役割と“どこまで自動？”

- **PUB（公開）**：自動  
    公式サイト・プレス・登記/官報・採用・企業ブログ・ニュースを MCP の**Web/Docsコネクタ**で取得→GPT/Geminiで抽出・要約・正規化。
    
- **EXT（外部推計）**：自動（APIが許す範囲）  
    Similarweb/Crunchbase/G2 など **API認証があるものだけ** MCPツール化。無い場合は「保留」扱い。
    
- **ANL（分析）**：自動（穴は pending）  
    LTV/CAC・TAM/SAM/SOM・Comps・DCF・リターンは数式ドリブン。依存セルが欠けると **`status:"pending"`** のままに。
    
- **CONF（機密）**：半自動  
    GDrive/Notion から MCP で取り込み → GPTが項目抽出 → **確認スイッチ**で確定。機微は**自動マスキング**。
    
- **INT（インタビュー）**：最後に不足だけ  
    ギャップ検出Botが**質問票**を自動生成。記録（音声/テキスト）はGPTで**要点抽出→欠落セルに追記→再計算**。
    

---

# データ設計（最小コア）

**1) 観測テーブル（ソース別の事実単位）**

```json
{
  "entity_id": "company:acme",
  "section": "business_model|market|team|deal|kpi",
  "field": "arr|arpu|churn|employee_count|pre_money",
  "value": "123.4",
  "unit": "USD_millions|%",
  "source_tag": "PUB|EXT|CONF|INT|ANL",
  "evidence": "url_or_file_id",
  "as_of": "2025-09-28",
  "disclosure": "IC|LP|LP+NDA|Private",
  "confidence": 0.0
}
```

**2) 依存セル（ANL用）**

```json
{
  "calc_id": "ltv_calc_v1",
  "requires": ["arpu","gross_margin","retention_months"],
  "status": "ready|pending",
  "value": null,
  "notes": "retention_months pending from INT"
}
```

**3) ドキュメント構成**

```json
{
  "template": "IC_v2",
  "sections": [
    {"id":"summary","source":"synth"},
    {"id":"why_now","source":"PUB,EXT"},
    {"id":"business","source":"PUB,CONF,ANL"},
    {"id":"team","source":"PUB,CONF"},
    {"id":"market","source":"EXT,ANL"},
    {"id":"competition","source":"PUB,EXT,ANL"},
    {"id":"deal","source":"CONF"},
    {"id":"valuation_returns","source":"ANL,CONF"},
    {"id":"risks_mitigations","source":"ANL,INT,CONF"},
    {"id":"value_up","source":"ANL,INT"},
    {"id":"dd_summary","source":"CONF"}
  ]
}
```

---

# MCP × GPT/Gemini の役割分担

- **MCPルーター**：  
    LLMからの「ツール呼び出し」を受け、各コネクタ（WebFetch、GDrive、Notion、Crunchbase等）に**共通IF**で中継。  
    _LLM側には1つの仮想ツール `mcp.execute(tool, args)` として見せる_。
    
- **GPT（OpenAI API）**：
    
    - 事実抽出、正規化、JSON構造化、項目マッピング、要約・執筆（日本語安定）。
        
    - 構造化出力（JSONモード）と**関数呼び出し**で堅牢に。
        
- **Gemini**：
    
    - 長文理解・図表含む資料読み込みの**冗長入力**、比較サマリや**裏取り**に併用。
        
    - 画像/表やPDFのレイアウト復元を伴う読解で補完。
        

> どちらも**同一スキーマ**で出力させ、オーケストレータがマージ（重複除去・信頼度マージ）。

---

# エージェント設計（プロンプト骨子）

1. **PUB収集Bot**（GPT）
    

- 目的：公式/PR/登記/採用/ブログ/ニュースから**事実のみ**抽出
    
- 出力：上記「観測テーブル」の配列（JSON）
    
- ガード：数値に**期間/分母/通貨**、主張に**出典URL**必須。推測禁止。
    

2. **EXT収集Bot**（GPT）
    

- 目的：API応答を**同スキーマ**に正規化
    
- 出力：観測テーブル
    
- ガード：推計には `confidence` を0.5未満で付与、**注意書き**自動付与。
    

3. **正規化＆重複排除Bot**（GPT）
    

- 目的：同一指標の競合値をマージ（優先：CONF > INT > PUB > EXT）
    
- 出力：正規化済みレコード＋**競合ログ**。
    

4. **ギャップ検出Bot**（GPT）
    

- 目的：テンプレ必須項目の未充足→**質問票/資料依頼票**生成
    
- 出力：`pending_list[]`（質問文、依頼資料、想定回答フォーマット、優先度）。
    

5. **CONFインジェスタ**（GPT）
    

- 目的：TermSheet/CapTable/モデル/契約の**項目抽出**（半自動承認）
    
- 出力：観測テーブル＋条項要約（条項→標準語彙に正規化）
    
- マスキング：社名→「業種/規模帯」、金額→レンジ表記（LP版）。
    

6. **ANLエンジン**（GPT or ルール＋Python）
    

- 目的：LTV/CAC、TAM/SAM/SOM、Comps、DCF、シナリオMOIC/IRR
    
- 出力：計算セル、`pending`があれば**そのまま穴**にして公開。
    
- ガード：**式・前提・出所**を隣接プロパティで必須出力。
    

7. **INT支援Bot**（GPT）
    

- 目的：`pending_list`から**役職別質問票**→議事録→**欠落セル埋め**。
    
- 出力：観測テーブルの更新差分。
    

8. **資料ビルダー**（GPT + テンプレ）
    

- 目的：IC版/LP版（自動マスキング）Markdown/Docs生成
    
- 出力：章立て本文＋脚注（出典埋め込み）＋差分サマリ。
    

---

# 疑似コード（最小構成・Node/Pythonどちらでも）

```pseudo
onProjectUpdated(projectId):
  sources = []
  sources += callLLM("PUBBot", mcp.execute("web.search+fetch", queries))
  sources += callLLM("EXTBot", mcp.execute("ext.api.batch", providers))
  norm = callLLM("NormalizeBot", {inputs: sources})

  gaps = callLLM("GapBot", {template: IC_template, inputs: norm})

  if hasNewConfUploads(projectId):
     conf = mcp.execute("gdrive.list+download", {folder: projectId})
     conf_extracted = callLLM("CONFIngestor", conf)
     norm = merge(norm, conf_extracted, precedence=CONF)

  anl = runANL({norm})  // ルール＋LLM併用、pendingは残す

  if gaps.pendingCount > 0 and userWantsINT:
     q = callLLM("INTDraft", {pending: gaps})
     // 面談後、録音/メモを投入
     int_updates = callLLM("INTFiller", {transcript})
     norm = merge(norm, int_updates)

  doc_ic = callLLM("DocBuilder", {norm, anl, mode: "IC"})
  doc_lp = callLLM("DocBuilder", {norm, anl, mode: "LP"})
  export(doc_ic, "GoogleDocs")
  export(doc_lp, "GoogleDocs")
```

---

# プロンプト雛形（抜粋）

**共通システムメッセージ**

- 出力は必ず`観測テーブル`のJSON配列。
    
- 各要素に `source_tag/evidence/as_of/disclosure/confidence` を付与。
    
- 推測は`confidence < 0.5`で明示。未確定は生成しない。
    

**ギャップ検出**

- テンプレ必須フィールド一覧を渡す → 欠落は `pending_list` に  
    `{"field":"ltv.retention_months","why":"INT必要","suggested_ask":"過去12ヶ月の月次残存率(%)を..", "owner":"CFO"}`
    

**資料ビルダー**

- モード=IC/LP を渡し、LPでは `disclosure != "LP"` を自動マスク。
    
- 章ごとに「結論→根拠→出典」構成。脚注に evidence をURL化。
    

---

# セキュリティ／開示管理

- **CONFの外部送信を極小化**：要約・抽出に必要な**抜粋だけ**LLMに渡す（全文は保管側）。
    
- **自動マスキング**：社名・契約条件・単価などはLP版でレンジ/匿名化。
    
- **監査ログ**：誰が何を確定したか（半自動承認の履歴）を保存。
    
- **API鍵**：MCPサーバに保管、LLMには渡さない。
    

---

# 品質ガード（自動チェック）

- **脚注率**：数値・主張の**出典付与率が100%**でなければNG。
    
- **定義一貫性**：ARR/ARPU/Churnなど**定義辞書**に一致しない場合は差し戻し。
    
- **日付鮮度**：`as_of`が古い指標は黄色警告。
    
- **数字の単位/分母**：欠落時は未通過。
    
- **EXTの注意書き**：推計には自動で但し書き。
    

---

# MVP → 本番の段階導入

**Phase 1（2–3週間）**

- MCP：WebFetch、GDrive、Notion のみ
    
- エージェント：PUB収集、正規化、ギャップ検出、資料ビルダー
    
- 出力：LP版ドラフト（CONFなしで回る箇所のみ）
    

**Phase 2**

- CONFインジェスタ（半自動承認UI）、ANL（LTV/CAC/TAM/Comps）
    
- 自動マスキングと差分サマリ
    

**Phase 3**

- EXT API（Crunchbase/Similarweb 等）連携、INT支援（議事→自動追記）
    
- シナリオ別MOIC/IRR、IC版とLP版の同時生成
    

---

# 具体的な実装メモ

- **オーケストレーション**：軽量なら Cloud Functions / Lambda、複雑なら Temporal/Celery。
    
- **ストレージ**：Postgres（観測テーブル/依存セル/監査ログ）、GCS/S3（原本ファイル）。
    
- **ドキュメント**：Google Docs API でテンプレ差し込み／Markdown基点でも可。
    
- **LLM呼び分け**：
    
    - 構造化抽出/執筆＝**GPT**（JSONモード/関数呼び出しが堅い）
        
    - 冗長ドキュメントの要約・比較＝**Gemini** 併用
        
- **MCP**：`web.fetch / web.search / gdrive.* / notion.* / ext.*` をツール定義。  
    LLM側は `mcp.execute({tool, args})` の**単一関数**で呼ぶ設計が運用しやすい。
    

---

# 成果物イメージ（自動最終化）

- **IC版**：フル開示＋デューデリ要約＋トップリスク×対策表＋次回KPI
    
- **LP版**：機微マスク済み＋脚注付き＋1枚サマリー（結論→根拠→リスク→次マイルストン）
    
- どちらも**差分サマリー**を冒頭（前回からの更新点/数値変更/新規リスク）。
    

---

必要なら、この設計の**Notion DBスキーマ（テーブル定義）**／**Google Docsテンプレ**／**プロンプト実体**をそのまま配布できる形で作ります。