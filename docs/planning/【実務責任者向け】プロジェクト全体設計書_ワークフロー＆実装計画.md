# 【実務責任者向け】プロジェクト全体設計書_ワークフロー＆実装計画

**作成日**: 2025-10-15
**対象**: プロジェクト責任者、実務担当マネージャー
**前提**: AI知識あり、Python経験なし（Claude Code等でコーディング可能）
**作業時間**: 平日毎日1時間程度

---

## 📋 目次

1. [プロジェクト概要](#プロジェクト概要)
2. [現状の課題と解決策](#現状の課題と解決策)
3. [プロダクト全体像](#プロダクト全体像)
4. [ワークフロー詳細](#ワークフロー詳細)
5. [自動化範囲と手動作業の境界](#自動化範囲と手動作業の境界)
6. [実装スケジュール（9ヶ月）](#実装スケジュール9ヶ月)
7. [各フェーズの成果物とコスト](#各フェーズの成果物とコスト)
8. [リスクと対応策](#リスクと対応策)
9. [投資判断の推奨](#投資判断の推奨)

---

## 🎯 プロジェクト概要

### プロジェクト名
**投資委員会資料作成の半自動化システム構築**

### 目的
VC投資委員会資料の作成時間を**43-65時間/案件 → 10-15時間/案件（70%削減）**に短縮し、データ品質と一貫性を向上させる。

### 実装者
- **人数**: 1名（あなた）
- **前提スキル**: AI理解、非エンジニア、Claude Code等でコーディング可能
- **作業時間**: 平日毎日1時間（週5時間）

### 期間とコスト
- **期間**: 9ヶ月（36週）
- **総コスト**: ¥242,500（API費用 + 開発ツール費用）
- **削減効果**: ¥8,550,000（9ヶ月累積、月5案件想定）
- **ROI**: 3,427%

---

## 📊 現状の課題と解決策

### 現状の課題

| 課題 | 現状 | 影響 |
|------|------|------|
| **作業時間** | 43-65時間/案件 | 案件数の増加に対応困難 |
| **情報収集** | 企業サイト、プレスリリースを手動収集 | 20-30時間 |
| **データ整理** | 複数ソースの情報を手動で照合 | 10-15時間 |
| **資料作成** | Word/PPTに手動でコピペ | 8-12時間 |
| **品質** | 人間のミス（転記ミス、矛盾見逃し） | 信頼性低下 |
| **属人化** | 担当者によってフォーマットが異なる | 標準化困難 |
| **LP版作成** | IC版から手動でマスキング | 3-5時間 |

### 解決策：AIによる半自動化

```
┌──────────────────────────────────────────────────────┐
│ 現状: 43-65時間/案件                                  │
│ ├ 情報収集: 20-30時間（手動）                         │
│ ├ データ整理: 10-15時間（手動）                       │
│ ├ 分析: 5-8時間（手動）                               │
│ └ 資料作成: 8-12時間（手動）                          │
└──────────────────────────────────────────────────────┘
                        ↓
                  【AI自動化】
                        ↓
┌──────────────────────────────────────────────────────┐
│ 目標: 10-15時間/案件（70%削減）                       │
│ ├ 情報収集: 3-5時間（AI自動）← 85%削減               │
│ ├ データ整理: 2-3時間（AI自動）← 80%削減             │
│ ├ 分析: 1-2時間（AI自動）← 75%削減                   │
│ └ 資料作成: 2-3時間（AI自動）← 75%削減               │
│                                                      │
│ 人間の作業: 確認・承認・最終調整のみ                  │
└──────────────────────────────────────────────────────┘
```

---

## 🏗️ プロダクト全体像

### システムアーキテクチャ（3層構造）

```
┌───────────────────────────────────────────────────────┐
│                  ① 情報収集層                          │
│               (Collection Layer)                      │
├───────────────────────────────────────────────────────┤
│ 【PUB収集】企業サイト、プレスリリース、採用ページ      │
│ → AI（LLM）が自動で情報を抽出                         │
│                                                       │
│ 【CONF処理】Term Sheet、Cap Table（PDF/Excel）        │
│ → AI（LLM）が抽出 + 人間が承認                        │
│                                                       │
│ 【EXT統合】Crunchbase、Similarweb等の外部データ       │
│ → APIで自動取得                                        │
└───────────────────────────────────────────────────────┘
                        ↓
┌───────────────────────────────────────────────────────┐
│                  ② データ処理層                        │
│              (Processing Layer)                       │
├───────────────────────────────────────────────────────┤
│ 【正規化】複数ソースのデータを統合                     │
│ → 優先順位: CONF > INT > PUB > EXT                   │
│                                                       │
│ 【矛盾検出】同じ項目で値が違う場合、Red/Yellow Flag   │
│ → 10%以内: OK、30%以上: 要確認                        │
│                                                       │
│ 【ギャップ検出】不足している情報をリストアップ         │
│ → Critical/High/Medium/Lowで優先度付け                │
│                                                       │
│ 【分析】ユニットエコノミクス、市場規模、バリュエーション│
│ → 自動計算                                             │
└───────────────────────────────────────────────────────┘
                        ↓
┌───────────────────────────────────────────────────────┐
│                  ③ 出力生成層                          │
│                (Output Layer)                         │
├───────────────────────────────────────────────────────┤
│ 【IC版レポート】機密情報を含む完全版                   │
│ → Markdown/PDF形式で自動生成                          │
│                                                       │
│ 【LP版レポート】社名・数値を自動マスキング             │
│ → 開示レベルに応じて自動調整                          │
└───────────────────────────────────────────────────────┘
```

### コアコンセプト：観測テーブル

**従来の方法**:
```
企業A = { 社名, 設立日, ARR, 従業員数, ... }
→ 問題: 情報源が不明、矛盾検出困難
```

**新しい方法**:
```
観測1 = { 企業A, ARR, 500万円, 出典: 公式サイト }
観測2 = { 企業A, ARR, 520万円, 出典: Term Sheet }
→ 利点: 情報源が明確、矛盾を自動検出
```

すべての情報を「観測」として記録することで：
- ✅ トレーサビリティ確保（どこから取得したか明確）
- ✅ 矛盾を自動検出（複数ソースで値が違う場合）
- ✅ 開示レベル管理（IC版/LP版の自動切り替え）

---

## 🔄 ワークフロー詳細

### 1案件の処理フロー（自動化後）

```
┌─────────────────────────────────────────────────────┐
│ Step 1: 案件登録（手動・1分）                        │
├─────────────────────────────────────────────────────┤
│ あなた: コマンドで企業IDを登録                       │
│ $ python cli.py create-entity "Acme Inc"           │
│ → システムが企業ID「company:acme」を生成             │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│ Step 2: 公開情報収集（AI自動・10分）                 │
├─────────────────────────────────────────────────────┤
│ あなた: 企業URLを指定してコマンド実行                │
│ $ python cli.py collect company:acme \             │
│   https://acme.com                                 │
│                                                    │
│ AI（LLM）の自動処理:                                │
│ ① 企業サイトのHTMLを取得                            │
│ ② 会社名、設立年、従業員数、事業内容を抽出           │
│ ③ プレスリリースから資金調達情報を抽出               │
│ ④ 採用ページから技術スタック・組織規模を推定         │
│ ⑤ データベースに保存                                │
│                                                    │
│ 結果: 15-20件の情報を自動取得                        │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│ Step 3: 外部データ統合（AI自動・5分）                │
├─────────────────────────────────────────────────────┤
│ あなた: コマンド実行                                 │
│ $ python cli.py integrate-external company:acme   │
│                                                    │
│ AI（API連携）の自動処理:                            │
│ ① Crunchbaseから資金調達履歴を取得                  │
│ ② Similarwebからトラフィック推定を取得              │
│ ③ 既存の公開情報と照合・矛盾チェック                 │
│ ④ データベースに追加保存                             │
│                                                    │
│ 結果: 8-10件の情報を追加                            │
│ 矛盾検出: funding_total（PUB: $5M, EXT: $5.2M）    │
│ → 🟡 Yellow Flag（10-30%の差異）                   │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│ Step 4: 機密資料処理（半自動・30分）                 │
├─────────────────────────────────────────────────────┤
│ あなた: Term Sheet（PDF）をアップロード              │
│ $ python cli.py process-conf company:acme \       │
│   term_sheet.pdf                                   │
│                                                    │
│ AI（LLM）の自動処理:                                │
│ ① PDFからテキストを抽出                             │
│ ② プレマネー評価額、投資額、持分を抽出               │
│ ③ Cap Tableを解析（完全希薄化計算）                 │
│ ④ 抽出結果を表示                                     │
│                                                    │
│ あなた（人間）: 抽出結果を確認                       │
│ $ python cli.py approve-conf approval_123         │
│ → プレビュー画面で内容を確認                         │
│ → 承認/却下/修正を選択                              │
│ → 承認後にデータベースに保存                         │
│                                                    │
│ 理由: 機密情報は100%の精度が必要なため人間が最終確認 │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│ Step 5: データ正規化（AI自動・1分）                  │
├─────────────────────────────────────────────────────┤
│ あなた: コマンド実行                                 │
│ $ python cli.py normalize company:acme            │
│                                                    │
│ AI（ロジック）の自動処理:                           │
│ ① 同じ項目の複数の値を検出                          │
│    例: ARR（PUB: $5M、CONF: $5.2M）                │
│ ② 優先順位でマージ                                  │
│    → CONF > INT > PUB > EXT                       │
│ ③ 正規化された値を採用                              │
│    → ARR: $5.2M（CONF）を採用                      │
│ ④ 差異が大きい場合はRed/Yellow Flagを立てる          │
│                                                    │
│ 結果: 正規化完了、矛盾は自動検出済み                  │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│ Step 6: ギャップ検出（AI自動・1分）                  │
├─────────────────────────────────────────────────────┤
│ あなた: コマンド実行                                 │
│ $ python cli.py detect-gaps company:acme          │
│                                                    │
│ AI（ロジック）の自動処理:                           │
│ ① テンプレートの必須項目リストを読み込み             │
│ ② データベースと照合                                │
│ ③ 不足情報をリストアップ                            │
│                                                    │
│ 結果表示:                                           │
│ 完成度: 78%                                         │
│ ❌ Critical不足: 2件                                │
│   - pre_money_valuation                           │
│   - cap_table                                     │
│ ⚠️ High不足: 3件                                   │
│   - management_background                         │
│   - market_size_tam                               │
│   - competitive_landscape                         │
│                                                    │
│ あなた: 不足情報を追加収集（手動で追加可能）          │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│ Step 7: 分析実行（AI自動・5分）                      │
├─────────────────────────────────────────────────────┤
│ あなた: コマンド実行                                 │
│ $ python cli.py analyze company:acme              │
│                                                    │
│ AI（計算）の自動処理:                               │
│ ① ユニットエコノミクス計算                          │
│    - LTV/CAC比率: 4.2（優良）                      │
│    - ペイバック期間: 8ヶ月                          │
│ ② 市場規模推定                                      │
│    - TAM: $10B、SAM: $2B、SOM: $200M             │
│ ③ バリュエーション分析                              │
│    - Comps分析: $50M-$80M                         │
│ ④ 結果をデータベースに保存                          │
│                                                    │
│ 結果: 分析完了、レポート生成の準備完了               │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│ Step 8: レポート生成（AI自動・5分）                  │
├─────────────────────────────────────────────────────┤
│ あなた: コマンド実行                                 │
│ $ python cli.py generate-report company:acme \    │
│   --version ic                                     │
│                                                    │
│ AI（テンプレート）の自動処理:                        │
│ ① データベースから全データを取得                     │
│ ② テンプレートに注入                                │
│ ③ 出典・脚注を自動付与                              │
│ ④ IC版Markdownを生成                               │
│                                                    │
│ 結果: output/company_acme_ic_20251015.md          │
│                                                    │
│ ────────────────────────────────────────            │
│                                                    │
│ LP版の生成（AI自動マスキング）:                      │
│ $ python cli.py generate-report company:acme \    │
│   --version lp                                     │
│                                                    │
│ AI（マスキング）の自動処理:                         │
│ ① 社名をマスキング                                  │
│    「Acme Inc」→「[SaaS] [シリーズA]」             │
│ ② 数値をレンジ化                                    │
│    「ARR: $5.2M」→「ARR: $5-10M」                 │
│ ③ 機密情報（disclosure=IC）を除外                   │
│ ④ LP版Markdownを生成                               │
│                                                    │
│ 結果: output/company_acme_lp_20251015.md          │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│ Step 9: 最終確認（手動・10-20分）                    │
├─────────────────────────────────────────────────────┤
│ あなた: 生成されたMarkdownを確認                     │
│ ① 内容の正確性チェック                              │
│ ② 矛盾フラグの確認と対応                            │
│ ③ 文章の微調整（必要に応じて）                      │
│ ④ 最終承認                                          │
└─────────────────────────────────────────────────────┘
```

### 作業時間の比較

| ステップ | 現状（手動） | 自動化後 | 削減率 |
|---------|------------|---------|--------|
| Step 1: 案件登録 | 5分 | 1分 | - |
| Step 2: 公開情報収集 | 20-30時間 | 10分（AI） | 99%削減 |
| Step 3: 外部データ統合 | 10-15時間 | 5分（AI） | 99%削減 |
| Step 4: 機密資料処理 | 8-12時間 | 30分（半自動） | 95%削減 |
| Step 5: データ正規化 | 3-5時間 | 1分（AI） | 99%削減 |
| Step 6: ギャップ検出 | 2-3時間 | 1分（AI） | 99%削減 |
| Step 7: 分析実行 | 5-8時間 | 5分（AI） | 99%削減 |
| Step 8: レポート生成 | 8-12時間 | 5分（AI） | 99%削減 |
| Step 9: 最終確認 | 2-3時間 | 10-20分 | 90%削減 |
| **合計** | **43-65時間** | **1-2時間** | **97%削減** |

---

## 🔀 自動化範囲と手動作業の境界

### 完全自動化（AIのみ）

```
✅ 自動化される作業:

1. 公開情報収集
   - 企業サイトのスクレイピング
   - プレスリリースの取得
   - 採用ページの解析
   → LLMが自動で情報を抽出

2. 外部データ統合
   - Crunchbase API呼び出し
   - Similarweb API呼び出し
   → 自動でデータ取得・保存

3. データ正規化
   - 複数ソースのマージ
   - 優先順位による調停
   → ルールベースで自動処理

4. 矛盾検出
   - 同じ項目の差異チェック
   - Red/Yellow Flagの付与
   → 自動で矛盾を検出

5. ギャップ検出
   - テンプレートとの差分チェック
   → 不足情報を自動リストアップ

6. 分析実行
   - ユニットエコノミクス計算
   - 市場規模推定
   - バリュエーション分析
   → 数式による自動計算

7. レポート生成
   - IC版Markdown生成
   - LP版マスキング
   → テンプレートエンジンで自動生成
```

### 半自動化（AI抽出 + 人間承認）

```
⚠️ 人間の承認が必要な作業:

1. 機密資料処理（CONF）
   - Term Sheet の抽出
   - Cap Table の解析
   → AIが抽出 → あなたが確認・承認

   理由: 機密情報は100%の精度が必要
   時間: 30分/案件
```

### 完全手動（人間のみ）

```
👤 あなたが行う作業:

1. 案件登録（1分）
   - コマンドで企業IDを作成

2. コマンド実行（各1分）
   - 各ステップでコマンドを実行
   - 進捗を確認

3. 機密資料の承認（30分）
   - AI抽出結果を確認
   - 承認/却下/修正

4. 不足情報の追加（任意）
   - ギャップ検出で指摘された情報を手動追加

5. 最終確認と調整（10-20分）
   - 生成されたレポートを確認
   - 必要に応じて微調整
```

### 自動化の割合

```
┌──────────────────────────────────────┐
│ 作業全体（43-65時間）                 │
├──────────────────────────────────────┤
│ ████████████████████████ 85% 自動化  │
│ ██ 10% 半自動化（AI+人間承認）        │
│ █ 5% 完全手動（コマンド実行・最終確認）│
└──────────────────────────────────────┘

結果: 43-65時間 → 1-2時間（97%削減）
```

---

## 📅 実装スケジュール（9ヶ月）

### 前提条件

- **作業者**: あなた1人
- **作業時間**: 平日毎日1時間（週5時間）
- **スキル**: AI理解、Python未経験、Claude Code使用可能
- **AIツール**: Claude Code、Cursor、ChatGPT を活用

### 全体スケジュール

```
┌────────┬──────────────────┬────────┬──────────┬──────────┐
│ 期間   │ フェーズ          │ 週     │ 累積時間 │ コスト   │
├────────┼──────────────────┼────────┼──────────┼──────────┤
│ Month1 │ Phase 0: 準備     │ W1-4   │ 20h      │ ¥8,000   │
│        │ ・環境構築        │        │          │          │
│        │ ・プロトタイプ    │        │          │          │
├────────┼──────────────────┼────────┼──────────┼──────────┤
│ Month2 │ Phase 1: PUB収集 │ W5-8   │ 20h      │ ¥27,500  │
│ Month3 │ （前半）          │ W9-12  │ 20h      │ ¥27,500  │
│        │ ・情報収集自動化  │        │          │          │
├────────┼──────────────────┼────────┼──────────┼──────────┤
│ Month4 │ Phase 2: 統合     │ W13-18 │ 30h      │ ¥45,000  │
│        │ ・外部API連携     │        │          │          │
│        │ ・正規化エンジン  │        │          │          │
├────────┼──────────────────┼────────┼──────────┼──────────┤
│ Month5 │ Phase 3: CONF     │ W19-24 │ 30h      │ ¥57,000  │
│        │ ・PDF処理         │        │          │          │
│        │ ・承認フロー      │        │          │          │
├────────┼──────────────────┼────────┼──────────┼──────────┤
│ Month6 │ Phase 4: 分析     │ W25-30 │ 30h      │ ¥37,500  │
│        │ ・計算エンジン    │        │          │          │
├────────┼──────────────────┼────────┼──────────┼──────────┤
│ Month7 │ Phase 5: レポート │ W31-36 │ 30h      │ ¥45,000  │
│ Month8 │ （前半）          │        │          │          │
│        │ ・テンプレート    │        │          │          │
│        │ ・マスキング      │        │          │          │
├────────┼──────────────────┼────────┼──────────┼──────────┤
│ Month9 │ 統合テスト        │        │ 20h      │ ¥0       │
│        │ ・最終調整        │        │          │          │
└────────┴──────────────────┴────────┴──────────┴──────────┘

合計: 36週（9ヶ月） / 180時間 / ¥242,500
```

### 週次スケジュール（1週間の例）

```
【Week 1の例】（Phase 0: 環境構築）

月曜日（1時間）: プロジェクト構造作成
├ タスク: ディレクトリ作成、Git初期化
├ AIツール: Claude Code にディレクトリ構造を生成させる
└ 成果物: 基本構造完成

火曜日（1時間）: API キー取得と設定
├ タスク: OpenAI/Gemini APIキー取得
├ AIツール: ChatGPT に .env ファイルの書き方を聞く
└ 成果物: API接続準備完了

水曜日（1時間）: LLM API 動作確認
├ タスク: 簡単なテストコード実行
├ AIツール: Cursor でコードを実行、エラーがあればデバッグ
└ 成果物: API接続確認

木曜日（1時間）: Web 取得テスト
├ タスク: 企業サイトを取得してHTMLを取得
├ AIツール: Claude Code にスクレイピングコードを書かせる
└ 成果物: Web取得機能完成

金曜日（1時間）: 統合テスト
├ タスク: Web取得 → LLM抽出 → 結果保存の流れをテスト
├ AIツール: Cursor Composer で全体を統合
└ 成果物: プロトタイプ完成
```

### 月次マイルストーン

| 月 | マイルストーン | Go/No-Go判断 |
|----|--------------|-------------|
| **Month 1** | プロトタイプ完成 | 1社で80%以上抽出できたか？ |
| **Month 3** | PUB収集完成 | 10社で90%精度達成したか？ |
| **Month 4** | データ統合完成 | 矛盾検出が正常に動作するか？ |
| **Month 5** | CONF処理完成 | 承認フローが使いやすいか？ |
| **Month 6** | 分析機能完成 | 計算が正確に動作するか？ |
| **Month 8** | レポート生成完成 | IC版/LP版が正しく生成されるか？ |
| **Month 9** | 本格導入 | 実案件で使えるレベルか？ |

---

## 💰 各フェーズの成果物とコスト

### Phase 0: 準備・技術検証（Week 1-4）

**期間**: 4週間（20時間）
**コスト**: ¥8,000

**やること**:
```
Week 1: 環境構築
├ ディレクトリ作成
├ API キー取得
├ LLM 動作確認
└ Web 取得テスト

Week 2: データモデル設計
├ 観測テーブル設計
├ データベース初期化
└ CRUD 操作実装

Week 3-4: プロトタイプ作成
├ 公開情報収集エンジン実装
├ 1社での抽出テスト
└ 精度検証（80%以上）
```

**成果物**:
- ✅ 開発環境セットアップ完了
- ✅ 1社の企業情報を80%以上抽出
- ✅ データベースに保存成功

**判定**:
- Go → Phase 1へ進む
- No-Go → プロンプト改善、再実施

---

### Phase 1: PUB自動収集（Week 5-12）

**期間**: 8週間（40時間）
**コスト**: ¥50,000

**やること**:
```
Week 5-6: 情報源の拡張
├ プレスリリース収集
├ 採用ページ解析
└ 複数ページ統合

Week 7-8: バッチ処理
├ 10社同時処理
├ キャッシング実装
└ 並列処理（非同期）

Week 9-10: 品質向上
├ プロンプト改善
├ 信頼度スコアリング
└ 異常値検出

Week 11-12: CLI ツール実装
├ コマンド実装（Click）
├ 進捗表示
└ エラーハンドリング
```

**成果物**:
- ✅ 10社で精度90%以上達成
- ✅ PUB収集時間 20-30時間 → 10分（99%削減）
- ✅ CLIツールで簡単に実行可能

**判定**:
- Go → Phase 2へ進む（**本番運用も開始可能**）
- No-Go → 精度改善に集中

**このフェーズの価値**:
- 💰 既にこの時点で大幅な時間削減を実感
- 💰 投資回収も開始（Phase 1完成後2週間で回収）

---

### Phase 2: データ統合・正規化（Week 13-18）

**期間**: 6週間（30時間）
**コスト**: ¥45,000

**やること**:
```
Week 13-14: 外部API統合
├ Crunchbase 連携
├ Similarweb 連携
└ 観測テーブルに追加保存

Week 15-16: 正規化エンジン
├ 優先順位マージ実装
├ 矛盾検出ロジック
└ Red/Yellow Flag 付与

Week 17-18: ギャップ検出
├ テンプレート定義
├ 不足情報検出
└ 優先度付け
```

**成果物**:
- ✅ 外部データ自動統合
- ✅ 矛盾を自動検出（Red/Yellow Flag）
- ✅ 不足情報を自動リストアップ

**削減効果**:
- データ整合性チェック 10-15時間 → 1分（99%削減）

---

### Phase 3: CONF半自動処理（Week 19-24）

**期間**: 6週間（30時間）
**コスト**: ¥57,000

**やること**:
```
Week 19-20: ファイル処理
├ PDF からテキスト抽出
├ Excel 読み込み
└ ファイル暗号化

Week 21-22: 情報抽出
├ Term Sheet 抽出
├ Cap Table 解析
└ 条項の標準化

Week 23-24: 承認フロー
├ 抽出結果のプレビュー表示
├ 承認/却下/修正の実装
└ 承認後の自動保存
```

**成果物**:
- ✅ PDF/Excel から自動抽出（精度95%）
- ✅ 人間承認フロー実装
- ✅ セキュリティ対策完了

**削減効果**:
- CONF情報整理 8-12時間 → 30分（95%削減）

---

### Phase 4: 分析自動化（Week 25-30）

**期間**: 6週間（30時間）
**コスト**: ¥37,500

**やること**:
```
Week 25-26: ユニットエコノミクス
├ LTV/CAC 計算
├ ペイバック期間計算
└ ベンチマーク比較

Week 27-28: 市場規模推定
├ TAM/SAM/SOM 計算
├ トップダウン/ボトムアップ
└ 成長率予測

Week 29-30: バリュエーション
├ Comparables 分析
├ 簡易DCF計算
└ リターン分析
```

**成果物**:
- ✅ ユニットエコノミクス自動計算
- ✅ 市場規模推定
- ✅ バリュエーション分析

**削減効果**:
- 財務分析 5-8時間 → 5分（98%削減）

---

### Phase 5: レポート自動生成（Week 31-36）

**期間**: 6週間（30時間）
**コスト**: ¥45,000

**やること**:
```
Week 31-32: テンプレートエンジン
├ Jinja2 テンプレート作成
├ IC版レポート設計
└ 出典の自動付与

Week 33-34: LP版マスキング
├ 社名マスキング実装
├ 数値レンジ化
└ 機密情報除外

Week 35-36: 統合テスト
├ 3案件での全フローテスト
├ エラーケース洗い出し
└ 最終調整
```

**成果物**:
- ✅ IC版レポート自動生成
- ✅ LP版自動マスキング
- ✅ 全フロー完成

**削減効果**:
- レポート作成 8-12時間 → 5分（99%削減）

---

## ⚠️ リスクと対応策

### 技術リスク

| リスク | 確率 | 影響 | 対応策 |
|--------|------|------|--------|
| **LLM精度不足** | 中 | 中 | プロンプト改善、Few-Shot Examples追加 |
| **API障害** | 低 | 高 | Geminiへのフォールバック実装 |
| **開発遅延** | 中 | 低 | スコープ調整、優先度の見直し |
| **コスト超過** | 低 | 中 | gpt-4o-mini 活用、キャッシング強化 |

### ビジネスリスク

| リスク | 確率 | 影響 | 対応策 |
|--------|------|------|--------|
| **効果不足** | 低 | 高 | Phase 1で早期検証、No-Go判断を設定 |
| **仕様変更** | 中 | 中 | アジャイル開発、柔軟な設計 |
| **採用率低下** | 中 | 中 | トレーニング実施、成功事例の共有 |

### リスク管理戦略

#### 段階的検証（Go/No-Go判断）

```
Week 4（Phase 0完了）
├ 検証: 1社で80%以上抽出できたか？
├ Go → Phase 1へ
└ No-Go → プロンプト改善、LLMモデル変更

Week 12（Phase 1完了）
├ 検証: 10社で90%精度、時間削減85%以上？
├ Go → Phase 2へ（本番運用も開始）
└ No-Go → 一時停止、精度改善に集中

Week 24（Phase 3完了）
├ 検証: CONF抽出精度95%、承認フロー動作？
├ Go → Phase 4-5へ
└ No-Go → 人間チェック強化で運用継続
```

---

## 💡 投資判断の推奨

### 投資額と効果

| 項目 | 金額 |
|------|------|
| **総投資額**（9ヶ月） | ¥242,500 |
| **削減効果**（9ヶ月累積、月5案件） | ¥8,550,000 |
| **ROI** | **3,427%** |
| **投資回収期間** | **Phase 1完了後 約2週間** |

### Go判断の条件

✅ **以下のすべてを満たす場合、投資を推奨**:

1. **案件数**: 月3案件以上
2. **予算**: ¥30,000/月を確保可能
3. **工数**: 週5時間（平日1時間）を確保可能
4. **期間**: 9ヶ月の投資期間を許容

### 感度分析

| シナリオ | 案件数/月 | 削減時間/案件 | 月間削減額 | 9ヶ月累積 | ROI | 投資回収 |
|---------|----------|-------------|-----------|----------|-----|---------|
| **楽観的** | 10案件 | 38時間 | ¥1,900,000 | ¥17,100,000 | 6,951% | 4日 |
| **標準** | 5案件 | 38時間 | ¥950,000 | ¥8,550,000 | 3,427% | 1週間 |
| **保守的** | 3案件 | 30時間 | ¥450,000 | ¥4,050,000 | 1,570% | 2週間 |
| **悲観的** | 2案件 | 20時間 | ¥200,000 | ¥1,800,000 | 642% | 5週間 |

**結論**: 最悪のシナリオでも**ROI 642%**を達成

---

## 📝 まとめ

### プロジェクトの本質

このプロジェクトは、**AI（LLM）の力を借りて、VC投資委員会資料作成の97%を自動化する**ものです。

```
┌───────────────────────────────────────────────┐
│ 現状: 43-65時間/案件（すべて手動）            │
└───────────────────────────────────────────────┘
                    ↓
           【AIによる半自動化】
                    ↓
┌───────────────────────────────────────────────┐
│ 目標: 1-2時間/案件（97%自動化）               │
│                                               │
│ 人間の作業:                                    │
│ ① コマンド実行（各1分）                       │
│ ② 機密資料の承認（30分）                      │
│ ③ 最終確認（10-20分）                         │
│                                               │
│ AIの作業:                                      │
│ ① 公開情報収集（自動）                        │
│ ② データ統合・正規化（自動）                  │
│ ③ 分析実行（自動）                            │
│ ④ レポート生成（自動）                        │
└───────────────────────────────────────────────┘
```

### 実装者に求められるスキル

- ✅ AI（LLM）の理解
- ✅ Claude Code / Cursor 等のAIツールの活用能力
- ✅ 調べながら進める力
- ❌ Python の深い知識は不要（AIが書いてくれる）

### スケジュール

- **期間**: 9ヶ月（36週）
- **作業時間**: 平日毎日1時間（週5時間）
- **累積時間**: 180時間

### コスト

- **総額**: ¥242,500
- **内訳**: API費用（¥197,500）+ 開発ツール（¥45,000）

### 投資対効果

- **削減効果**: ¥8,550,000（9ヶ月累積）
- **ROI**: 3,427%
- **投資回収期間**: 約2週間

### 推奨

✅ **Go判断を推奨**

理由:
1. ROIが非常に高い（最悪でも642%）
2. 段階的検証でリスクを最小化
3. Phase 1完成時点で大きな効果を実感
4. 投資回収が極めて早い（2週間）

---

**次のアクション**: Week 1 Day 1から実装を開始しましょう！

**保存先**: `C:\Users\81801\Documents\obsidian_toto\70_Projects\Fund\【実務責任者向け】プロジェクト全体設計書_ワークフロー＆実装計画.md`
