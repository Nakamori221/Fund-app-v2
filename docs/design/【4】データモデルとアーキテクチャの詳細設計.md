実装に向けて、具体的なデータベーススキーマとシステムアーキテクチャを設計します。

# データモデル・アーキテクチャ設計

## 1. データベーススキーマ（PostgreSQL）

### 1-1. コアテーブル

#### cases（案件マスター）

```sql
CREATE TABLE cases (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_name VARCHAR(255) NOT NULL,
    stage VARCHAR(50) NOT NULL, -- 'seed', 'early', 'growth', 'late'
    status VARCHAR(50) NOT NULL DEFAULT 'draft', -- 'draft', 'in_progress', 'ready_for_ic', 'approved', 'passed'
    
    -- 基本情報
    location VARCHAR(255),
    founded_date DATE,
    website_url TEXT,
    
    -- 担当情報
    lead_partner_id UUID REFERENCES users(id),
    analyst_id UUID REFERENCES users(id),
    
    -- プロセス管理
    discovered_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    first_meeting_at TIMESTAMPTZ,
    ic_date TIMESTAMPTZ,
    decision VARCHAR(50), -- 'approved', 'rejected', 'deferred'
    decision_at TIMESTAMPTZ,
    
    -- メタデータ
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    -- 検索用
    search_vector tsvector GENERATED ALWAYS AS (
        to_tsvector('japanese', coalesce(company_name, '') || ' ' || coalesce(location, ''))
    ) STORED
);

CREATE INDEX idx_cases_status ON cases(status);
CREATE INDEX idx_cases_stage ON cases(stage);
CREATE INDEX idx_cases_search ON cases USING GIN(search_vector);
CREATE INDEX idx_cases_lead_partner ON cases(lead_partner_id);
```

#### observations（観測テーブル - すべての情報の単一ソース）

```sql
CREATE TABLE observations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    case_id UUID NOT NULL REFERENCES cases(id) ON DELETE CASCADE,
    
    -- 分類
    section VARCHAR(100) NOT NULL, -- 'basic_info', 'finance', 'team', 'market', 'product', 'kpi'
    field VARCHAR(100) NOT NULL, -- 'arr', 'employee_count', 'pre_money_valuation'等
    
    -- 値
    value_type VARCHAR(50) NOT NULL, -- 'number', 'string', 'date', 'boolean', 'json'
    value_number NUMERIC,
    value_string TEXT,
    value_date DATE,
    value_boolean BOOLEAN,
    value_json JSONB,
    
    unit VARCHAR(50), -- 'JPY', 'USD', 'persons', '%'
    
    -- メタデータ
    source_tag VARCHAR(10) NOT NULL, -- 'PUB', 'EXT', 'INT', 'CONF', 'ANL'
    evidence TEXT NOT NULL, -- URL or file reference
    as_of DATE NOT NULL, -- データの時点
    
    -- 品質管理
    confidence NUMERIC(3,2) CHECK (confidence >= 0 AND confidence <= 1),
    disclosure_level VARCHAR(20) NOT NULL DEFAULT 'IC', -- 'IC', 'LP', 'LP_NDA', 'PRIVATE'
    
    -- 承認ワークフロー
    requires_approval BOOLEAN DEFAULT false,
    approved_by UUID REFERENCES users(id),
    approved_at TIMESTAMPTZ,
    
    notes TEXT,
    
    -- 監査
    created_by UUID REFERENCES users(id),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    -- 一意性制約（同じケース・セクション・フィールド・時点・ソースの重複を防ぐ）
    UNIQUE(case_id, section, field, as_of, source_tag)
);

CREATE INDEX idx_observations_case ON observations(case_id);
CREATE INDEX idx_observations_field ON observations(field);
CREATE INDEX idx_observations_source ON observations(source_tag);
CREATE INDEX idx_observations_section ON observations(section);
CREATE INDEX idx_observations_approval ON observations(requires_approval, approved_at);
```

#### calculations（計算結果と依存関係）

```sql
CREATE TABLE calculations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    case_id UUID NOT NULL REFERENCES cases(id) ON DELETE CASCADE,
    
    calc_type VARCHAR(100) NOT NULL, -- 'ltv', 'cac', 'tam', 'valuation_dcf'
    
    -- 依存するobservationsのID
    depends_on UUID[] NOT NULL DEFAULT '{}',
    
    -- 計算結果
    status VARCHAR(50) NOT NULL DEFAULT 'pending', -- 'pending', 'ready', 'complete', 'error'
    result JSONB,
    
    -- 計算式と前提
    formula TEXT,
    assumptions JSONB,
    
    -- エラー情報
    error_message TEXT,
    missing_parameters TEXT[],
    
    -- メタデータ
    calculated_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_calculations_case ON calculations(case_id);
CREATE INDEX idx_calculations_status ON calculations(status);
CREATE INDEX idx_calculations_type ON calculations(calc_type);
```

#### conflicts（矛盾検出ログ）

```sql
CREATE TABLE conflicts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    case_id UUID NOT NULL REFERENCES cases(id) ON DELETE CASCADE,
    
    field VARCHAR(100) NOT NULL,
    
    -- 競合する観測値
    observation_ids UUID[] NOT NULL,
    
    -- 差異の詳細
    deviation_pct NUMERIC(5,2),
    conflict_type VARCHAR(50), -- 'temporal', 'definition', 'value', 'unknown'
    severity VARCHAR(20) NOT NULL, -- 'info', 'warning', 'error', 'critical'
    
    -- 解決状況
    status VARCHAR(50) NOT NULL DEFAULT 'detected', -- 'detected', 'auto_resolved', 'escalated', 'resolved'
    resolution_method VARCHAR(100), -- 'use_latest', 'keep_both', 'human_decision'
    resolved_by UUID REFERENCES users(id),
    resolved_at TIMESTAMPTZ,
    
    resolution_notes TEXT,
    
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_conflicts_case ON conflicts(case_id);
CREATE INDEX idx_conflicts_status ON conflicts(status);
CREATE INDEX idx_conflicts_severity ON conflicts(severity);
```

### 1-2. 文書管理テーブル

#### documents（アップロードされた文書）

```sql
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    case_id UUID NOT NULL REFERENCES cases(id) ON DELETE CASCADE,
    
    -- ファイル情報
    filename VARCHAR(500) NOT NULL,
    file_type VARCHAR(50) NOT NULL, -- 'pdf', 'xlsx', 'docx', 'pptx'
    file_size_bytes BIGINT NOT NULL,
    storage_path TEXT NOT NULL, -- S3/GCS path
    
    -- 分類
    doc_type VARCHAR(50) NOT NULL, -- 'term_sheet', 'cap_table', 'financial_model', 'pitch_deck'
    classification_level VARCHAR(20) NOT NULL, -- 'L0'-'L4'
    
    -- 処理状況
    processing_status VARCHAR(50) NOT NULL DEFAULT 'uploaded', -- 'uploaded', 'processing', 'extracted', 'error'
    extracted_data JSONB,
    extraction_error TEXT,
    
    -- セキュリティ
    virus_scan_status VARCHAR(50) DEFAULT 'pending',
    virus_scan_result TEXT,
    
    -- 承認
    requires_approval BOOLEAN DEFAULT true,
    approved_by UUID REFERENCES users(id),
    approved_at TIMESTAMPTZ,
    
    uploaded_by UUID REFERENCES users(id),
    uploaded_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_documents_case ON documents(case_id);
CREATE INDEX idx_documents_type ON documents(doc_type);
CREATE INDEX idx_documents_processing ON documents(processing_status);
```

#### generated_reports（生成されたレポート）

```sql
CREATE TABLE generated_reports (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    case_id UUID NOT NULL REFERENCES cases(id) ON DELETE CASCADE,
    
    report_type VARCHAR(50) NOT NULL, -- 'ic_draft', 'ic_final', 'lp_version'
    version INTEGER NOT NULL DEFAULT 1,
    
    -- 内容
    content_markdown TEXT,
    content_html TEXT,
    export_url TEXT, -- Google Docs URL or PDF path
    
    -- 完成度
    completion_rate NUMERIC(3,2),
    pending_items TEXT[],
    
    -- 差分情報（前バージョンからの変更）
    diff_summary TEXT,
    
    generated_by VARCHAR(50) NOT NULL, -- 'system', 'user:{id}'
    generated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    UNIQUE(case_id, report_type, version)
);

CREATE INDEX idx_reports_case ON generated_reports(case_id);
CREATE INDEX idx_reports_type ON generated_reports(report_type);
```

### 1-3. ワークフロー管理テーブル

#### tasks（タスクと質問票）

```sql
CREATE TABLE tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    case_id UUID NOT NULL REFERENCES cases(id) ON DELETE CASCADE,
    
    task_type VARCHAR(50) NOT NULL, -- 'int_question', 'conf_request', 'data_verification', 'approval'
    title VARCHAR(500) NOT NULL,
    description TEXT,
    
    -- 優先度
    priority VARCHAR(20) NOT NULL DEFAULT 'medium', -- 'low', 'medium', 'high', 'critical'
    importance VARCHAR(20), -- 'critical', 'high', 'medium', 'low'
    
    -- 担当
    assigned_to UUID REFERENCES users(id),
    target_role VARCHAR(100), -- 'CEO', 'CFO', 'CTO'（インタビュー質問の場合）
    
    -- ステータス
    status VARCHAR(50) NOT NULL DEFAULT 'open', -- 'open', 'in_progress', 'completed', 'cancelled'
    
    -- 回答・結果
    response TEXT,
    response_attachments TEXT[],
    completed_at TIMESTAMPTZ,
    
    -- 期限
    due_date DATE,
    
    created_by UUID REFERENCES users(id),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_tasks_case ON tasks(case_id);
CREATE INDEX idx_tasks_assigned ON tasks(assigned_to);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_priority ON tasks(priority);
```

#### workflow_stages（処理ステージの進捗）

```sql
CREATE TABLE workflow_stages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    case_id UUID NOT NULL REFERENCES cases(id) ON DELETE CASCADE,
    
    stage_name VARCHAR(100) NOT NULL, -- 'pub_collection', 'ext_collection', 'conf_processing', 'anl_calculation', 'int_execution', 'report_generation'
    
    status VARCHAR(50) NOT NULL DEFAULT 'not_started', -- 'not_started', 'in_progress', 'completed', 'error', 'blocked'
    progress NUMERIC(3,2) DEFAULT 0, -- 0.00 to 1.00
    
    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,
    
    error_message TEXT,
    blocked_by VARCHAR(100), -- 他のステージ名
    
    -- 詳細メトリクス
    metrics JSONB, -- {'items_processed': 10, 'items_total': 15, 'duration_seconds': 120}
    
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_workflow_case ON workflow_stages(case_id);
CREATE INDEX idx_workflow_status ON workflow_stages(status);
```

### 1-4. 監査・セキュリティテーブル

#### audit_logs（全活動のログ）

```sql
CREATE TABLE audit_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    
    -- アクション
    action VARCHAR(100) NOT NULL, -- 'view', 'edit', 'create', 'delete', 'export', 'llm_call', 'approve'
    resource_type VARCHAR(100) NOT NULL, -- 'case', 'observation', 'document', 'report'
    resource_id UUID,
    
    -- アクター
    user_id UUID REFERENCES users(id),
    ip_address INET,
    user_agent TEXT,
    
    -- データ分類（セキュリティ重要度）
    data_classification VARCHAR(20), -- 'L0'-'L4'
    
    -- 詳細
    details JSONB,
    
    -- LLMコールの場合
    llm_provider VARCHAR(50),
    llm_model VARCHAR(100),
    data_sent_size_bytes INTEGER,
    
    -- 結果
    result VARCHAR(50) NOT NULL, -- 'success', 'failure', 'partial'
    error_message TEXT,
    
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_audit_user ON audit_logs(user_id);
CREATE INDEX idx_audit_action ON audit_logs(action);
CREATE INDEX idx_audit_resource ON audit_logs(resource_type, resource_id);
CREATE INDEX idx_audit_timestamp ON audit_logs(timestamp DESC);
CREATE INDEX idx_audit_classification ON audit_logs(data_classification);
```

#### access_tokens（API認証）

```sql
CREATE TABLE access_tokens (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id),
    
    token_hash VARCHAR(256) NOT NULL UNIQUE,
    
    -- 権限
    scopes TEXT[] NOT NULL DEFAULT '{}',
    
    -- 有効期限
    expires_at TIMESTAMPTZ NOT NULL,
    
    -- 最終利用
    last_used_at TIMESTAMPTZ,
    last_used_ip INET,
    
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_tokens_user ON access_tokens(user_id);
CREATE INDEX idx_tokens_expiry ON access_tokens(expires_at);
```

---

## 2. システムアーキテクチャ

### 2-1. 全体構成図（テキスト版）

```
┌─────────────────────────────────────────────────────────────┐
│                        ユーザー層                            │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐                 │
│  │ Webブラウザ│  │ モバイル │  │ Slack Bot │                 │
│  └─────┬────┘  └─────┬────┘  └─────┬────┘                 │
└────────┼─────────────┼─────────────┼────────────────────────┘
         │             │             │
         └─────────────┴─────────────┘
                       │
         ┌─────────────▼─────────────┐
         │     API Gateway           │
         │  (認証・レート制限・ログ)  │
         └─────────────┬─────────────┘
                       │
         ┌─────────────▼─────────────────────────────────┐
         │           アプリケーション層                   │
         │                                                │
         │  ┌──────────────┐  ┌──────────────┐          │
         │  │  Web API     │  │ Workflow     │          │
         │  │  (FastAPI)   │  │ Orchestrator │          │
         │  └──────┬───────┘  └──────┬───────┘          │
         │         │                  │                   │
         │  ┌──────▼──────────────────▼───────┐          │
         │  │      Agent Framework             │          │
         │  │  ┌─────────────────────────┐    │          │
         │  │  │ PUB Bot │ EXT Bot       │    │          │
         │  │  │ Normalizer │ Gap Detector│    │          │
         │  │  │ CONF Processor │ ANL Engine│  │          │
         │  │  └─────────────────────────┘    │          │
         │  └──────────────┬──────────────────┘          │
         └─────────────────┼─────────────────────────────┘
                           │
         ┌─────────────────▼─────────────────────────────┐
         │          MCP (Model Context Protocol)         │
         │                                                │
         │  ┌──────────┐ ┌──────────┐ ┌──────────┐      │
         │  │Web Fetch │ │ GDrive   │ │ Notion   │      │
         │  └──────────┘ └──────────┘ └──────────┘      │
         │  ┌──────────┐ ┌──────────┐ ┌──────────┐      │
         │  │Crunchbase│ │Similarweb│ │LinkedIn  │      │
         │  └──────────┘ └──────────┘ └──────────┘      │
         └─────────────────┬─────────────────────────────┘
                           │
         ┌─────────────────▼─────────────────────────────┐
         │              LLM層                             │
         │                                                │
         │  ┌──────────┐ ┌──────────┐ ┌──────────┐      │
         │  │ OpenAI   │ │ Gemini   │ │ Claude   │      │
         │  │ GPT-4o   │ │ 1.5 Pro  │ │ (予備)   │      │
         │  └──────────┘ └──────────┘ └──────────┘      │
         └────────────────────────────────────────────────┘
                           │
         ┌─────────────────▼─────────────────────────────┐
         │            データ層                            │
         │                                                │
         │  ┌──────────────┐  ┌──────────────┐          │
         │  │ PostgreSQL   │  │ Redis        │          │
         │  │ (メインDB)    │  │ (キャッシュ)  │          │
         │  └──────────────┘  └──────────────┘          │
         │  ┌──────────────┐  ┌──────────────┐          │
         │  │ S3/GCS       │  │ Elasticsearch│          │
         │  │ (ファイル)    │  │ (全文検索)    │          │
         │  └──────────────┘  └──────────────┘          │
         └────────────────────────────────────────────────┘
```

### 2-2. コンポーネント詳細

#### API Gateway（Kong / AWS API Gateway / Cloud Endpoints）

**責務:**
- 認証・認可（JWT検証）
- レート制限（100 req/min per user）
- ログ記録
- CORS設定
- TLS終端

**設定例:**
```yaml
rate_limits:
  - route: /api/v1/cases
    limit: 100
    window: 60s
    
  - route: /api/v1/llm/*
    limit: 10
    window: 60s

auth:
  jwt:
    issuer: "https://auth.fund.example.com"
    audience: "api.fund.example.com"
```

#### Web API (FastAPI)

**エンドポイント設計:**

```python
# main.py
from fastapi import FastAPI, Depends, HTTPException
from fastapi.security import HTTPBearer

app = FastAPI(title="Fund IC Automation API", version="1.0.0")

# 認証
security = HTTPBearer()

# Cases API
@app.post("/api/v1/cases", response_model=CaseResponse)
async def create_case(
    case: CaseCreate,
    current_user: User = Depends(get_current_user)
):
    """新規案件の作成"""
    pass

@app.get("/api/v1/cases/{case_id}")
async def get_case(case_id: UUID):
    """案件詳細の取得"""
    pass

@app.get("/api/v1/cases/{case_id}/observations")
async def get_observations(
    case_id: UUID,
    section: Optional[str] = None,
    source_tag: Optional[str] = None
):
    """観測データの取得（フィルタリング可能）"""
    pass

@app.post("/api/v1/cases/{case_id}/observations")
async def create_observation(case_id: UUID, obs: ObservationCreate):
    """観測データの手動追加"""
    pass

@app.patch("/api/v1/observations/{obs_id}")
async def update_observation(obs_id: UUID, update: ObservationUpdate):
    """観測データの更新"""
    pass

# Documents API
@app.post("/api/v1/cases/{case_id}/documents")
async def upload_document(
    case_id: UUID,
    file: UploadFile,
    doc_type: str
):
    """文書のアップロード"""
    pass

@app.get("/api/v1/documents/{doc_id}/extract")
async def trigger_extraction(doc_id: UUID):
    """文書からの情報抽出をトリガー"""
    pass

# Workflow API
@app.post("/api/v1/cases/{case_id}/workflow/start")
async def start_workflow(case_id: UUID):
    """自動ワークフローの開始"""
    pass

@app.get("/api/v1/cases/{case_id}/workflow/status")
async def get_workflow_status(case_id: UUID):
    """ワークフローの進捗確認"""
    pass

# Reports API
@app.post("/api/v1/cases/{case_id}/reports/generate")
async def generate_report(
    case_id: UUID,
    report_type: str  # 'ic' or 'lp'
):
    """レポート生成"""
    pass

@app.get("/api/v1/reports/{report_id}")
async def get_report(report_id: UUID):
    """生成されたレポートの取得"""
    pass

# Tasks API
@app.get("/api/v1/cases/{case_id}/tasks")
async def get_tasks(case_id: UUID, status: Optional[str] = None):
    """タスク一覧"""
    pass

@app.patch("/api/v1/tasks/{task_id}")
async def update_task(task_id: UUID, update: TaskUpdate):
    """タスクの更新（完了、回答追加等）"""
    pass

# Conflicts API
@app.get("/api/v1/cases/{case_id}/conflicts")
async def get_conflicts(case_id: UUID):
    """矛盾の一覧"""
    pass

@app.post("/api/v1/conflicts/{conflict_id}/resolve")
async def resolve_conflict(conflict_id: UUID, resolution: ConflictResolution):
    """矛盾の解決"""
    pass
```

#### Workflow Orchestrator（Temporal / Celery / Prefect）

**推奨: Temporal**（複雑なワークフローに最適）

```python
# workflow.py
from temporalio import workflow
from datetime import timedelta

@workflow.defn
class ICMaterialWorkflow:
    @workflow.run
    async def run(self, case_id: str) -> dict:
        # Phase 1: PUB収集
        pub_result = await workflow.execute_activity(
            collect_pub_info,
            case_id,
            start_to_close_timeout=timedelta(minutes=10)
        )
        
        # Phase 2: EXT収集（並列実行）
        ext_tasks = [
            workflow.execute_activity(
                call_crunchbase,
                case_id,
                start_to_close_timeout=timedelta(minutes=5)
            ),
            workflow.execute_activity(
                call_similarweb,
                case_id,
                start_to_close_timeout=timedelta(minutes=5)
            )
        ]
        ext_results = await asyncio.gather(*ext_tasks)
        
        # Phase 3: 正規化
        normalized = await workflow.execute_activity(
            normalize_observations,
            {"pub": pub_result, "ext": ext_results},
            start_to_close_timeout=timedelta(minutes=5)
        )
        
        # Phase 4: ギャップ検出
        gaps = await workflow.execute_activity(
            detect_gaps,
            normalized,
            start_to_close_timeout=timedelta(minutes=3)
        )
        
        # Phase 5: CONF処理（人間の承認を待つ）
        if has_pending_documents(case_id):
            # シグナルを待つ（人間が文書をアップロードするまで）
            await workflow.wait_condition(
                lambda: self.conf_ready,
                timeout=timedelta(days=7)
            )
            
            conf_result = await workflow.execute_activity(
                process_conf_documents,
                case_id,
                start_to_close_timeout=timedelta(minutes=15)
            )
        
        # Phase 6: ANL計算
        anl_result = await workflow.execute_activity(
            run_analysis,
            case_id,
            start_to_close_timeout=timedelta(minutes=10)
        )
        
        # Phase 7: レポート生成
        report = await workflow.execute_activity(
            generate_report,
            case_id,
            start_to_close_timeout=timedelta(minutes=5)
        )
        
        return {
            "status": "completed",
            "report_id": report["id"],
            "completion_rate": report["completion_rate"]
        }
    
    @workflow.signal
    def conf_documents_ready(self):
        """人間が文書をアップロードしたことをシグナル"""
        self.conf_ready = True
```

---

## 3. MCP実装の詳細

### 3-1. MCPサーバーの構成

```python
# mcp_server.py
from fastapi import FastAPI
from typing import Dict, Any

mcp_app = FastAPI()

# ツールレジストリ
TOOLS: Dict[str, callable] = {}

def register_tool(name: str):
    """デコレータでツールを登録"""
    def decorator(func):
        TOOLS[name] = func
        return func
    return decorator

@mcp_app.post("/execute")
async def execute_tool(request: ToolExecutionRequest):
    """
    LLMからのツール呼び出しを受け付ける
    """
    tool_name = request.tool
    args = request.arguments
    
    if tool_name not in TOOLS:
        raise HTTPException(404, f"Tool {tool_name} not found")
    
    try:
        result = await TOOLS[tool_name](**args)
        return {"status": "success", "result": result}
    except Exception as e:
        logger.error(f"Tool execution error: {e}")
        return {"status": "error", "error": str(e)}

# ツールの実装例
@register_tool("web.fetch")
async def web_fetch(url: str) -> Dict[str, Any]:
    """Webページの取得"""
    async with httpx.AsyncClient() as client:
        response = await client.get(
            url,
            headers={"User-Agent": "FundBot/1.0"},
            timeout=30
        )
        
        return {
            "url": url,
            "status_code": response.status_code,
            "content": response.text,
            "fetched_at": datetime.now().isoformat()
        }

@register_tool("gdrive.list")
async def gdrive_list_files(folder_id: str) -> List[Dict]:
    """Google Driveのファイル一覧"""
    service = get_gdrive_service()
    
    results = service.files().list(
        q=f"'{folder_id}' in parents",
        fields="files(id, name, mimeType, modifiedTime)"
    ).execute()
    
    return results.get('files', [])

@register_tool("gdrive.download")
async def gdrive_download(file_id: str) -> bytes:
    """Google Driveからファイルをダウンロード"""
    service = get_gdrive_service()
    
    request = service.files().get_media(fileId=file_id)
    file_content = request.execute()
    
    return file_content

@register_tool("crunchbase.company")
async def crunchbase_get_company(company_name: str) -> Dict:
    """Crunchbaseから企業情報を取得"""
    api_key = get_secret("CRUNCHBASE_API_KEY")
    
    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"https://api.crunchbase.com/api/v4/entities/organizations/{company_name}",
            headers={"X-cb-user-key": api_key}
        )
        
        return response.json()
```

### 3-2. LLMからのMCP呼び出し

```python
# agent.py
def call_llm_with_tools(prompt: str, tools: List[str]):
    """
    LLMにツール使用を許可して呼び出し
    """
    tools_schema = [get_tool_schema(t) for t in tools]
    
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ],
        tools=tools_schema,
        tool_choice="auto"
    )
    
    # ツール呼び出しがあるか確認
    if response.choices[0].message.tool_calls:
        results = []
        
        for tool_call in response.choices[0].message.tool_calls:
            # MCPサーバーにリクエスト
            result = await execute_mcp_tool(
                tool_call.function.name,
                json.loads(tool_call.function.arguments)
            )
            results.append(result)
        
        # 結果をLLMに返して最終応答を得る
        final_response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
                response.choices[0].message,
                {"role": "tool", "content": json.dumps(results)}
            ]
        )
        
        return final_response.choices[0].message.content
    
    return response.choices[0].message.content
```

---

## 4. スケーラビリティとパフォーマンス

### 4-1. キャッシング戦略

```python
# cache.py
import redis
from functools import wraps

redis_client = redis.Redis(
    host='localhost',
    port=6379,
    decode_responses=True
)

def cache_result(ttl: int = 3600):
    """結果をキャッシュするデコレータ"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # キャッシュキーの生成
            cache_key = f"{func.__name__}:{hash_args(args, kwargs)}"
            
            # キャッシュ確認
            cached = redis_client.get(cache_key)
            if cached:
                logger.info(f"Cache hit: {cache_key}")
                return json.loads(cached)
            
            # 実行してキャッシュ
            result = await func(*args, **kwargs)
            redis_client.setex(
                cache_key,
                ttl,
                json.dumps(result)
            )
            
            return result
        
        return wrapper
    return decorator

# 使用例
@cache_result(ttl=3600)
async def fetch_company_website(url: str):
    """会社Webサイトの取得（1時間キャッシュ）"""
    return await web_fetch(url)
```

### 4-2. バッチ処理とキューイング

```python
# worker.py（Celery使用）
from celery import Celery

celery_app = Celery('fund_automation')

@celery_app.task
def process_pub_collection(case_id: str):
    """PUB収集をバックグラウンドで実行"""
    try:
        result = collect_pub_info(case_id)
        save_observations(case_id, result)
        update_workflow_stage(case_id, 'pub_collection', 'completed')
    except Exception as e:
        logger.error(f"PUB collection failed: {e}")
        update_workflow_stage(case_id, 'pub_collection', 'error')

# 優先度付きキュー
@celery_app.task(queue='high_priority')
def urgent_task(case_id: str):
    """緊急タスク（ICが迫っている案件）"""
    pass

@celery_app.task(queue='low_priority')
def background_refresh(case_id: str):
    """バックグラウンドリフレッシュ"""
    pass
```

---

## 5. モニタリングとオブザーバビリティ

### 5-1. メトリクス収集（Prometheus）

```python
# metrics.py
from prometheus_client import Counter, Histogram, Gauge

# カウンター
api_requests_total = Counter(
    'api_requests_total',
    'Total API requests',
    ['method', 'endpoint', 'status']
)

llm_calls_total = Counter(
    'llm_calls_total',
    'Total LLM API calls',
    ['provider', 'model', 'status']
)

# ヒストグラム
api_request_duration = Histogram(
    'api_request_duration_seconds',
    'API request duration',
    ['endpoint']
)

llm_call_duration = Histogram(
    'llm_call_duration_seconds',
    'LLM call duration',
    ['provider', 'model']
)

# ゲージ
active_cases = Gauge(
    'active_cases',
    'Number of active cases',
    ['status']
)

pending_approvals = Gauge(
    'pending_approvals',
    'Number of items pending approval'
)
```

### 5-2. ログ集約（ELK Stack / DataDog）

```python
# logging_config.py
import logging
import json
from pythonjsonlogger import jsonlogger

# 構造化ログ
class CustomJsonFormatter(jsonlogger.JsonFormatter):
    def add_fields(self, log_record, record, message_dict):
        super().add_fields(log_record, record, message_dict)
        log_record['timestamp'] = datetime.utcnow().isoformat()
        log_record['service'] = 'fund-automation'
        log_record['environment'] = os.getenv('ENV', 'development')

logger = logging.getLogger()
handler = logging.StreamHandler()
handler.setFormatter(CustomJsonFormatter())
logger.addHandler(handler)

# 使用例
logger.info(
    "PUB collection completed",
    extra={
        "case_id": case_id,
        "duration_seconds": 12.5,
        "items_collected": 15
    }
)
```

---

このデータモデルとアーキテクチャ設計により、スケーラブルで保守性の高いシステムを構築できます。次のセクションでは、UI設計と人間承認フローについて詳述します。

